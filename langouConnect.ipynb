{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Compute source space connectivity and visualize it using a circular graph\n",
        "\n",
        "This example computes the all-to-all connectivity between 68 regions in\n",
        "source space based on dSPM inverse solutions and a FreeSurfer cortical\n",
        "parcellation. The connectivity is visualized using a circular graph which\n",
        "is ordered based on the locations of the regions in the axial plane.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 files missing from root.txt in /data/home/viscent/mne_data/MNE-fsaverage-data\n",
            "0 files missing from bem.txt in /data/home/viscent/mne_data/MNE-fsaverage-data/fsaverage\n",
            "Automatically created module for IPython interactive environment\n"
          ]
        }
      ],
      "source": [
        "# Authors: Martin Luessi <mluessi@nmr.mgh.harvard.edu>\n",
        "#          Alexandre Gramfort <alexandre.gramfort@inria.fr>\n",
        "#          Nicolas P. Rougier (graph code borrowed from his matplotlib gallery)\n",
        "#\n",
        "# License: BSD (3-clause)\n",
        "\n",
        "import numpy as np\n",
        "import os.path as op\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from langouEEG import *\n",
        "\n",
        "import mne\n",
        "import pickle\n",
        "from mne.datasets import sample\n",
        "from mne.minimum_norm import apply_inverse_epochs, read_inverse_operator\n",
        "from mne.connectivity import spectral_connectivity\n",
        "from mne.viz import circular_layout, plot_connectivity_circle\n",
        "import mne\n",
        "from mne.datasets import eegbci\n",
        "from mne.datasets import fetch_fsaverage\n",
        "from mne.datasets import sample\n",
        "from mne.minimum_norm import make_inverse_operator, apply_inverse\n",
        "from mne.minimum_norm import write_inverse_operator\n",
        "dataRoot = \"/data/home/viscent/Light\"\n",
        "# Download fsaverage files\n",
        "fs_dir = fetch_fsaverage(verbose=True)\n",
        "isMale = True\n",
        "result_dir = op.join(dataRoot,'result','male' if isMale else 'female')\n",
        "subjects_dir = op.dirname(fs_dir)\n",
        "\n",
        "# The files live in:\n",
        "subject = 'fsaverage'\n",
        "trans = 'fsaverage'  # MNE has a built-in fsaverage transformation\n",
        "src = op.join(fs_dir, 'bem', 'fsaverage-ico-5-src.fif')\n",
        "bem = op.join(fs_dir, 'bem', 'fsaverage-5120-5120-5120-bem-sol.fif')\n",
        "print(__doc__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adding average EEG reference projection.\n",
            "1 projection items deactivated\n",
            "Average reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\n",
            "file info:\n",
            "<Info | 11 non-empty values\n",
            " bads: 1 items (Trigger)\n",
            " ch_names: FP1, FPZ, FP2, AF3, AF4, F7, F5, F3, F1, FZ, F2, F4, F6, F8, ...\n",
            " chs: 64 EEG, 1 EOG, 1 STIM\n",
            " custom_ref_applied: False\n",
            " dig: 66 items (66 EEG)\n",
            " highpass: 0.1 Hz\n",
            " lowpass: 250.0 Hz\n",
            " meas_date: unspecified\n",
            " nchan: 66\n",
            " projs: Average EEG reference: off\n",
            " sfreq: 500.0 Hz\n",
            " subject_info: 5 items (dict)\n",
            ">\n",
            "channel names:\n",
            "['FP1', 'FPZ', 'FP2', 'AF3', 'AF4', 'F7', 'F5', 'F3', 'F1', 'FZ', 'F2', 'F4', 'F6', 'F8', 'FT7', 'FC5', 'FC3', 'FC1', 'FCZ', 'FC2', 'FC4', 'FC6', 'FT8', 'T7', 'C5', 'C3', 'C1', 'CZ', 'C2', 'C4', 'C6', 'T8', 'M1', 'TP7', 'CP5', 'CP3', 'CP1', 'CPZ', 'CP2', 'CP4', 'CP6', 'TP8', 'M2', 'P7', 'P5', 'P3', 'P1', 'PZ', 'P2', 'P4', 'P6', 'P8', 'PO7', 'PO5', 'PO3', 'POZ', 'PO4', 'PO6', 'PO8', 'CB1', 'O1', 'OZ', 'O2', 'CB2', 'VEO', 'Trigger']\n",
            "time period:\n",
            "1336150\n",
            "events:\n",
            "Used Annotations descriptions: ['11', '12', '255', '8', '9']\n",
            "{'random_flicker-60s': 1, 'random_rest-300s': 2, '40Hz_rest-300s': 3, '40Hz_flicker-60s': 4}\n",
            "Not setting metadata\n",
            "Not setting metadata\n",
            "5 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "Created an SSP operator (subspace dimension = 1)\n",
            "1 projection items activated\n",
            "Loading data for 5 events and 13501 original time points ...\n",
            "0 bad epochs dropped\n",
            "Not setting metadata\n",
            "Not setting metadata\n",
            "5 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "Created an SSP operator (subspace dimension = 1)\n",
            "1 projection items activated\n",
            "Loading data for 5 events and 30001 original time points ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-3-a08c027b5e98>:12: RuntimeWarning: The unit for channel(s) Trigger has changed from V to NA.\n",
            "  raw.set_channel_types({'Trigger':'stim','VEO':'eog'})\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 bad epochs dropped\n",
            "Not setting metadata\n",
            "Not setting metadata\n",
            "2 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "Created an SSP operator (subspace dimension = 1)\n",
            "1 projection items activated\n",
            "Loading data for 2 events and 30001 original time points ...\n",
            "0 bad epochs dropped\n",
            "Not setting metadata\n",
            "Not setting metadata\n",
            "6 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "Created an SSP operator (subspace dimension = 1)\n",
            "1 projection items activated\n",
            "Loading data for 6 events and 13501 original time points ...\n",
            "0 bad epochs dropped\n",
            "Not setting metadata\n",
            "Not setting metadata\n",
            "6 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "Created an SSP operator (subspace dimension = 1)\n",
            "1 projection items activated\n",
            "Loading data for 6 events and 13501 original time points ...\n",
            "0 bad epochs dropped\n",
            "Adding average EEG reference projection.\n",
            "1 projection items deactivated\n",
            "Average reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\n",
            "file info:\n",
            "<Info | 11 non-empty values\n",
            " bads: 1 items (Trigger)\n",
            " ch_names: FP1, FPZ, FP2, AF3, AF4, F7, F5, F3, F1, FZ, F2, F4, F6, F8, ...\n",
            " chs: 64 EEG, 1 EOG, 1 STIM\n",
            " custom_ref_applied: False\n",
            " dig: 66 items (66 EEG)\n",
            " highpass: 0.1 Hz\n",
            " lowpass: 250.0 Hz\n",
            " meas_date: unspecified\n",
            " nchan: 66\n",
            " projs: Average EEG reference: off\n",
            " sfreq: 500.0 Hz\n",
            " subject_info: 5 items (dict)\n",
            ">\n",
            "channel names:\n",
            "['FP1', 'FPZ', 'FP2', 'AF3', 'AF4', 'F7', 'F5', 'F3', 'F1', 'FZ', 'F2', 'F4', 'F6', 'F8', 'FT7', 'FC5', 'FC3', 'FC1', 'FCZ', 'FC2', 'FC4', 'FC6', 'FT8', 'T7', 'C5', 'C3', 'C1', 'CZ', 'C2', 'C4', 'C6', 'T8', 'M1', 'TP7', 'CP5', 'CP3', 'CP1', 'CPZ', 'CP2', 'CP4', 'CP6', 'TP8', 'M2', 'P7', 'P5', 'P3', 'P1', 'PZ', 'P2', 'P4', 'P6', 'P8', 'PO7', 'PO5', 'PO3', 'POZ', 'PO4', 'PO6', 'PO8', 'CB1', 'O1', 'OZ', 'O2', 'CB2', 'VEO', 'Trigger']\n",
            "time period:\n",
            "1242250\n",
            "events:\n",
            "Used Annotations descriptions: ['11', '12', '8', '9']\n",
            "{'random_flicker-60s': 1, 'random_rest-300s': 2, '40Hz_rest-300s': 3, '40Hz_flicker-60s': 4}\n",
            "Not setting metadata\n",
            "Not setting metadata\n",
            "5 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "Created an SSP operator (subspace dimension = 1)\n",
            "1 projection items activated\n",
            "Loading data for 5 events and 13501 original time points ...\n",
            "0 bad epochs dropped\n",
            "Not setting metadata\n",
            "Not setting metadata\n",
            "5 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "Created an SSP operator (subspace dimension = 1)\n",
            "1 projection items activated\n",
            "Loading data for 5 events and 30001 original time points ...\n",
            "0 bad epochs dropped\n",
            "Not setting metadata\n",
            "Not setting metadata\n",
            "6 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "Created an SSP operator (subspace dimension = 1)\n",
            "1 projection items activated\n",
            "Loading data for 6 events and 30001 original time points ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-3-a08c027b5e98>:12: RuntimeWarning: The unit for channel(s) Trigger has changed from V to NA.\n",
            "  raw.set_channel_types({'Trigger':'stim','VEO':'eog'})\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 bad epochs dropped\n",
            "Not setting metadata\n",
            "Not setting metadata\n",
            "6 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "Created an SSP operator (subspace dimension = 1)\n",
            "1 projection items activated\n",
            "Loading data for 6 events and 13501 original time points ...\n",
            "0 bad epochs dropped\n",
            "Not setting metadata\n",
            "Not setting metadata\n",
            "6 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "Created an SSP operator (subspace dimension = 1)\n",
            "1 projection items activated\n",
            "Loading data for 6 events and 13501 original time points ...\n",
            "0 bad epochs dropped\n",
            "Adding average EEG reference projection.\n",
            "1 projection items deactivated\n",
            "Average reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\n",
            "file info:\n",
            "<Info | 11 non-empty values\n",
            " bads: 1 items (Trigger)\n",
            " ch_names: FP1, FPZ, FP2, AF3, AF4, F7, F5, F3, F1, FZ, F2, F4, F6, F8, ...\n",
            " chs: 64 EEG, 1 EOG, 1 STIM\n",
            " custom_ref_applied: False\n",
            " dig: 66 items (66 EEG)\n",
            " highpass: 0.1 Hz\n",
            " lowpass: 250.0 Hz\n",
            " meas_date: unspecified\n",
            " nchan: 66\n",
            " projs: Average EEG reference: off\n",
            " sfreq: 500.0 Hz\n",
            " subject_info: 5 items (dict)\n",
            ">\n",
            "channel names:\n",
            "['FP1', 'FPZ', 'FP2', 'AF3', 'AF4', 'F7', 'F5', 'F3', 'F1', 'FZ', 'F2', 'F4', 'F6', 'F8', 'FT7', 'FC5', 'FC3', 'FC1', 'FCZ', 'FC2', 'FC4', 'FC6', 'FT8', 'T7', 'C5', 'C3', 'C1', 'CZ', 'C2', 'C4', 'C6', 'T8', 'M1', 'TP7', 'CP5', 'CP3', 'CP1', 'CPZ', 'CP2', 'CP4', 'CP6', 'TP8', 'M2', 'P7', 'P5', 'P3', 'P1', 'PZ', 'P2', 'P4', 'P6', 'P8', 'PO7', 'PO5', 'PO3', 'POZ', 'PO4', 'PO6', 'PO8', 'CB1', 'O1', 'OZ', 'O2', 'CB2', 'VEO', 'Trigger']\n",
            "time period:\n",
            "1562350\n",
            "events:\n",
            "Used Annotations descriptions: ['11', '12', '8', '9']\n",
            "{'random_flicker-60s': 1, 'random_rest-300s': 2, '40Hz_rest-300s': 3, '40Hz_flicker-60s': 4}\n",
            "Not setting metadata\n",
            "Not setting metadata\n",
            "5 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "Created an SSP operator (subspace dimension = 1)\n",
            "1 projection items activated\n",
            "Loading data for 5 events and 13501 original time points ...\n",
            "0 bad epochs dropped\n",
            "Not setting metadata\n",
            "Not setting metadata\n",
            "5 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "Created an SSP operator (subspace dimension = 1)\n",
            "1 projection items activated\n",
            "Loading data for 5 events and 30001 original time points ...\n",
            "1 bad epochs dropped\n",
            "Not setting metadata\n",
            "Not setting metadata\n",
            "9 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "Created an SSP operator (subspace dimension = 1)\n",
            "1 projection items activated\n",
            "Loading data for 9 events and 30001 original time points ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-3-a08c027b5e98>:12: RuntimeWarning: The unit for channel(s) Trigger has changed from V to NA.\n",
            "  raw.set_channel_types({'Trigger':'stim','VEO':'eog'})\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 bad epochs dropped\n",
            "Not setting metadata\n",
            "Not setting metadata\n",
            "9 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "Created an SSP operator (subspace dimension = 1)\n",
            "1 projection items activated\n",
            "Loading data for 9 events and 13501 original time points ...\n",
            "0 bad epochs dropped\n",
            "Not setting metadata\n",
            "Not setting metadata\n",
            "9 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "Created an SSP operator (subspace dimension = 1)\n",
            "1 projection items activated\n",
            "Loading data for 9 events and 13501 original time points ...\n",
            "0 bad epochs dropped\n",
            "Adding average EEG reference projection.\n",
            "1 projection items deactivated\n",
            "Average reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\n",
            "file info:\n",
            "<Info | 11 non-empty values\n",
            " bads: 1 items (Trigger)\n",
            " ch_names: FP1, FPZ, FP2, AF3, AF4, F7, F5, F3, F1, FZ, F2, F4, F6, F8, ...\n",
            " chs: 64 EEG, 1 EOG, 1 STIM\n",
            " custom_ref_applied: False\n",
            " dig: 66 items (66 EEG)\n",
            " highpass: 0.1 Hz\n",
            " lowpass: 250.0 Hz\n",
            " meas_date: unspecified\n",
            " nchan: 66\n",
            " projs: Average EEG reference: off\n",
            " sfreq: 500.0 Hz\n",
            " subject_info: 5 items (dict)\n",
            ">\n",
            "channel names:\n",
            "['FP1', 'FPZ', 'FP2', 'AF3', 'AF4', 'F7', 'F5', 'F3', 'F1', 'FZ', 'F2', 'F4', 'F6', 'F8', 'FT7', 'FC5', 'FC3', 'FC1', 'FCZ', 'FC2', 'FC4', 'FC6', 'FT8', 'T7', 'C5', 'C3', 'C1', 'CZ', 'C2', 'C4', 'C6', 'T8', 'M1', 'TP7', 'CP5', 'CP3', 'CP1', 'CPZ', 'CP2', 'CP4', 'CP6', 'TP8', 'M2', 'P7', 'P5', 'P3', 'P1', 'PZ', 'P2', 'P4', 'P6', 'P8', 'PO7', 'PO5', 'PO3', 'POZ', 'PO4', 'PO6', 'PO8', 'CB1', 'O1', 'OZ', 'O2', 'CB2', 'VEO', 'Trigger']\n",
            "time period:\n",
            "1091950\n",
            "events:\n",
            "Used Annotations descriptions: ['11', '12', '8', '9']\n",
            "{'random_flicker-60s': 1, 'random_rest-300s': 2, '40Hz_rest-300s': 3, '40Hz_flicker-60s': 4}\n",
            "Not setting metadata\n",
            "Not setting metadata\n",
            "5 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "Created an SSP operator (subspace dimension = 1)\n",
            "1 projection items activated\n",
            "Loading data for 5 events and 13501 original time points ...\n",
            "0 bad epochs dropped\n",
            "Not setting metadata\n",
            "Not setting metadata\n",
            "5 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "Created an SSP operator (subspace dimension = 1)\n",
            "1 projection items activated\n",
            "Loading data for 5 events and 30001 original time points ...\n",
            "1 bad epochs dropped\n",
            "Not setting metadata\n",
            "Not setting metadata\n",
            "5 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "Created an SSP operator (subspace dimension = 1)\n",
            "1 projection items activated\n",
            "Loading data for 5 events and 30001 original time points ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-3-a08c027b5e98>:12: RuntimeWarning: The unit for channel(s) Trigger has changed from V to NA.\n",
            "  raw.set_channel_types({'Trigger':'stim','VEO':'eog'})\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 bad epochs dropped\n",
            "Not setting metadata\n",
            "Not setting metadata\n",
            "5 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "Created an SSP operator (subspace dimension = 1)\n",
            "1 projection items activated\n",
            "Loading data for 5 events and 13501 original time points ...\n",
            "0 bad epochs dropped\n",
            "Not setting metadata\n",
            "Not setting metadata\n",
            "5 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "Created an SSP operator (subspace dimension = 1)\n",
            "1 projection items activated\n",
            "Loading data for 5 events and 13501 original time points ...\n",
            "0 bad epochs dropped\n",
            "Not setting metadata\n",
            "Not setting metadata\n",
            "26 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "Created an SSP operator (subspace dimension = 1)\n",
            "0 bad epochs dropped\n",
            "Not setting metadata\n",
            "Not setting metadata\n",
            "20 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "Created an SSP operator (subspace dimension = 1)\n",
            "0 bad epochs dropped\n"
          ]
        }
      ],
      "source": [
        "epochs_4F = []\n",
        "epochs_RF = []\n",
        "for subject_name in range(1,21):\n",
        "    if not (isMale ^ (subject_name in [7,8,11,17])):\n",
        "        continue\n",
        "    if subject_name<10:\n",
        "        subject_name='S0'+str(subject_name)\n",
        "    else:\n",
        "        subject_name='S'+str(subject_name)\n",
        "    with open(dataRoot+'/clean_data/'+subject_name+'_clean.lgeeg','rb') as f:\n",
        "        raw=pickle.load(f)\n",
        "    raw.set_channel_types({'Trigger':'stim','VEO':'eog'})\n",
        "    raw.set_eeg_reference(projection=True)\n",
        "    events, event_dict=extractEvents(raw)\n",
        "    picks = mne.pick_types(raw.info, meg=False, eeg=True, stim=False, eog=True,\n",
        "                        exclude='bads')\n",
        "    epoch_RR,epoch_RF,epoch_4R,epoch_4F = extractEpochs(raw,events,picks)\n",
        "    epochs_4F.append(epoch_4F)\n",
        "    epochs_RF.append(epoch_RF)\n",
        "epochs_4F = mne.concatenate_epochs(epochs_4F)\n",
        "epochs_RF = mne.concatenate_epochs(epochs_RF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load our data\n",
        "\n",
        "First we'll load the data we'll use in connectivity estimation. We'll use\n",
        "the sample MEG data provided with MNE.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adding average EEG reference projection.\n",
            "1 projection items deactivated\n",
            "Average reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\n",
            "file info:\n",
            "<Info | 11 non-empty values\n",
            " bads: 1 items (Trigger)\n",
            " ch_names: FP1, FPZ, FP2, AF3, AF4, F7, F5, F3, F1, FZ, F2, F4, F6, F8, ...\n",
            " chs: 64 EEG, 1 EOG, 1 STIM\n",
            " custom_ref_applied: False\n",
            " dig: 66 items (66 EEG)\n",
            " highpass: 0.1 Hz\n",
            " lowpass: 250.0 Hz\n",
            " meas_date: unspecified\n",
            " nchan: 66\n",
            " projs: Average EEG reference: off\n",
            " sfreq: 500.0 Hz\n",
            " subject_info: 5 items (dict)\n",
            ">\n",
            "channel names:\n",
            "['FP1', 'FPZ', 'FP2', 'AF3', 'AF4', 'F7', 'F5', 'F3', 'F1', 'FZ', 'F2', 'F4', 'F6', 'F8', 'FT7', 'FC5', 'FC3', 'FC1', 'FCZ', 'FC2', 'FC4', 'FC6', 'FT8', 'T7', 'C5', 'C3', 'C1', 'CZ', 'C2', 'C4', 'C6', 'T8', 'M1', 'TP7', 'CP5', 'CP3', 'CP1', 'CPZ', 'CP2', 'CP4', 'CP6', 'TP8', 'M2', 'P7', 'P5', 'P3', 'P1', 'PZ', 'P2', 'P4', 'P6', 'P8', 'PO7', 'PO5', 'PO3', 'POZ', 'PO4', 'PO6', 'PO8', 'CB1', 'O1', 'OZ', 'O2', 'CB2', 'VEO', 'Trigger']\n",
            "time period:\n",
            "1066650\n",
            "events:\n",
            "Used Annotations descriptions: ['11', '12', '8', '9']\n",
            "{'random_flicker-60s': 1, 'random_rest-300s': 2, '40Hz_rest-300s': 3, '40Hz_flicker-60s': 4}\n",
            "Reading forward solution from /data/home/viscent/Light/fwd_solutions/S15_fwd.lgeeg...\n",
            "    Reading a source space...\n",
            "    [done]\n",
            "    Reading a source space...\n",
            "    [done]\n",
            "    2 source spaces read\n",
            "    Desired named matrix (kind = 3523) not available\n",
            "    Read EEG forward solution (20484 sources, 64 channels, free orientations)\n",
            "    Source spaces transformed to the forward solution coordinate frame\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-4-6d6c946b1021>:4: RuntimeWarning: The unit for channel(s) Trigger has changed from V to NA.\n",
            "  raw.set_channel_types({'Trigger':'stim','VEO':'eog'})\n",
            "<ipython-input-4-6d6c946b1021>:13: RuntimeWarning: This filename (/data/home/viscent/Light/fwd_solutions/S15_fwd.lgeeg) does not conform to MNE naming conventions. All forward files should end with -fwd.fif, -fwd.fif.gz, _fwd.fif or _fwd.fif.gz\n",
            "  fwd = mne.read_forward_solution(os.path.join(dataRoot,'fwd_solutions',subject_name+'_fwd.lgeeg'))\n"
          ]
        }
      ],
      "source": [
        "subject_name='S15'\n",
        "with open(dataRoot+'/clean_data/'+subject_name+'_clean.lgeeg','rb') as f:\n",
        "    raw=pickle.load(f)\n",
        "raw.set_channel_types({'Trigger':'stim','VEO':'eog'})\n",
        "raw.set_eeg_reference(projection=True)\n",
        "events, event_dict=extractEvents(raw)\n",
        "if not op.exists(os.path.join(dataRoot,'fwd_solutions',subject_name+'_fwd.lgeeg')):\n",
        "    fwd = mne.make_forward_solution(raw.info, trans=trans, src=src,\n",
        "                                    bem=bem, eeg=True, mindist=5.0, n_jobs=1)\n",
        "    print(fwd)\n",
        "    mne.write_forward_solution(os.path.join(dataRoot,'fwd_solutions',subject_name+'_fwd.lgeeg'),fwd,overwrite=True)\n",
        "else:\n",
        "    fwd = mne.read_forward_solution(os.path.join(dataRoot,'fwd_solutions',subject_name+'_fwd.lgeeg'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Not setting metadata\n",
            "Not setting metadata\n",
            "5 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "Created an SSP operator (subspace dimension = 1)\n",
            "1 projection items activated\n",
            "Loading data for 5 events and 13501 original time points ...\n",
            "0 bad epochs dropped\n",
            "Not setting metadata\n",
            "Not setting metadata\n",
            "5 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "Created an SSP operator (subspace dimension = 1)\n",
            "1 projection items activated\n",
            "Loading data for 5 events and 30001 original time points ...\n",
            "1 bad epochs dropped\n",
            "Not setting metadata\n",
            "Not setting metadata\n",
            "5 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "Created an SSP operator (subspace dimension = 1)\n",
            "1 projection items activated\n",
            "Loading data for 5 events and 30001 original time points ...\n",
            "0 bad epochs dropped\n",
            "Not setting metadata\n",
            "Not setting metadata\n",
            "5 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "Created an SSP operator (subspace dimension = 1)\n",
            "1 projection items activated\n",
            "Loading data for 5 events and 13501 original time points ...\n",
            "0 bad epochs dropped\n",
            "Not setting metadata\n",
            "Not setting metadata\n",
            "5 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "Created an SSP operator (subspace dimension = 1)\n",
            "1 projection items activated\n",
            "Loading data for 5 events and 13501 original time points ...\n",
            "0 bad epochs dropped\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1.4e-09 (2.2e-16 eps * 64 dim * 1e+05  max singular value)\n",
            "    Estimated rank (eeg): 63\n",
            "    EEG: rank 63 computed from 64 data channels with 1 projector\n",
            "    Created an SSP operator (subspace dimension = 1)\n",
            "    Setting small EEG eigenvalues to zero (without PCA)\n",
            "Reducing data rank from 64 -> 63\n",
            "Estimating covariance using SHRUNK\n",
            "Done.\n",
            "Estimating covariance using EMPIRICAL\n",
            "Done.\n",
            "Using cross-validation to select the best estimator.\n",
            "Number of samples used : 40004\n",
            "log-likelihood on unseen data (descending order):\n",
            "   shrunk: -297.877\n",
            "   empirical: -492.723\n",
            "selecting best estimator: shrunk\n",
            "[done]\n",
            "Reading inverse operator decomposition from /data/home/viscent/Light/inv_operators/S15_inv.lgeeg...\n",
            "    Reading inverse operator info...\n",
            "    [done]\n",
            "    Reading inverse operator decomposition...\n",
            "    [done]\n",
            "    64 x 64 full covariance (kind = 1) found.\n",
            "    Read a total of 1 projection items:\n",
            "        Average EEG reference (1 x 64) active\n",
            "    Noise covariance matrix read.\n",
            "    61452 x 61452 diagonal covariance (kind = 2) found.\n",
            "    Source covariance matrix read.\n",
            "    61452 x 61452 diagonal covariance (kind = 6) found.\n",
            "    Orientation priors read.\n",
            "    61452 x 61452 diagonal covariance (kind = 5) found.\n",
            "    Depth priors read.\n",
            "    Did not find the desired covariance matrix (kind = 3)\n",
            "    Reading a source space...\n",
            "    [done]\n",
            "    Reading a source space...\n",
            "    [done]\n",
            "    2 source spaces read\n",
            "    Read a total of 1 projection items:\n",
            "        Average EEG reference (1 x 64) active\n",
            "    Source spaces transformed to the inverse solution coordinate frame\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-5-40558c20ecee>:30: RuntimeWarning: This filename (/data/home/viscent/Light/inv_operators/S15_inv.lgeeg) does not conform to MNE naming conventions. All inverse operator files should end with -inv.fif, -inv.fif.gz, _inv.fif or _inv.fif.gz\n",
            "  inverse_operator = read_inverse_operator(fname_inv)\n"
          ]
        }
      ],
      "source": [
        "data_path = sample.data_path()\n",
        "# subjects_dir = data_path + '/subjects'\n",
        "fname_inv = os.path.join(dataRoot,'inv_operators',subject_name+'_inv.lgeeg')\n",
        "# subject = 'sample'\n",
        "# fname_raw = data_path + '/MEG/sample/sample_audvis_filt-0-40_raw.fif'\n",
        "# fname_event = data_path + '/MEG/sample/sample_audvis_filt-0-40_raw-eve.fif'\n",
        "\n",
        "\n",
        "# Pick MEG channels\n",
        "picks = mne.pick_types(raw.info, meg=False, eeg=True, stim=False, eog=True,\n",
        "                       exclude='bads')\n",
        "\n",
        "epoch_RR,epoch_RF,epoch_4R,epoch_4F = extractEpochs(raw,events,picks)\n",
        "# evoked_4F = epoch_4F.average().pick('eeg')\n",
        "# Define epochs for left-auditory condition\n",
        "# event_id, tmin, tmax = 1, -0.2, 0.5\n",
        "# epochs = mne.Epochs(raw, events, event_id, tmin, tmax, picks=picks,\n",
        "                    # baseline=(None, 0), reject=dict(mag=4e-12, grad=4000e-13,\n",
        "                    #                                 eog=150e-6))\n",
        "\n",
        "\n",
        "noise_cov = mne.compute_covariance(\n",
        "    epoch_RR, tmax=80., method=['shrunk', 'empirical'], rank=None, verbose=True)\n",
        "if not os.path.exists(fname_inv):  \n",
        "    inverse_operator = make_inverse_operator(\n",
        "        epochs_4F.info, fwd, noise_cov, loose=0.2, depth=0.8)\n",
        "    write_inverse_operator(os.path.join(dataRoot,'inv_operators',subject_name+'_inv.lgeeg'),inverse_operator)\n",
        "else:   \n",
        "# Load data\n",
        "    inverse_operator = read_inverse_operator(fname_inv)\n",
        "# raw = mne.io.read_raw_fif(fname_raw)\n",
        "# events = mne.read_events(fname_event)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute inverse solutions and their connectivity\n",
        "\n",
        "Next, we need to compute the inverse solution for this data. This will return\n",
        "the sources / source activity that we'll use in computing connectivity. We'll\n",
        "compute the connectivity in the alpha band of these sources. We can specify\n",
        "particular frequencies to include in the connectivity with the ``fmin`` and\n",
        "``fmax`` flags. Notice from the status messages how mne-python:\n",
        "\n",
        "1. reads an epoch from the raw file\n",
        "2. applies SSP and baseline correction\n",
        "3. computes the inverse to obtain a source estimate\n",
        "4. averages the source estimate to obtain a time series for each label\n",
        "5. includes the label time series in the connectivity computation\n",
        "6. moves to the next epoch.\n",
        "\n",
        "This behaviour is because we are using generators. Since we only need to\n",
        "operate on the data one epoch at a time, using a generator allows us to\n",
        "compute connectivity in a computationally efficient manner where the amount\n",
        "of memory (RAM) needed is independent from the number of epochs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading labels from parcellation...\n",
            "   read 35 labels from /data/home/viscent/mne_data/MNE-fsaverage-data/fsaverage/label/lh.aparc.annot\n",
            "   read 34 labels from /data/home/viscent/mne_data/MNE-fsaverage-data/fsaverage/label/rh.aparc.annot\n"
          ]
        }
      ],
      "source": [
        "# Compute inverse solution and for each epoch. By using \"return_generator=True\"\n",
        "# stcs will be a generator object instead of a list.\n",
        "\n",
        "snr = 1.0  # use lower SNR for single epochs\n",
        "lambda2 = 1.0 / snr ** 2\n",
        "method = \"dSPM\"  # use dSPM method (could also be MNE or sLORETA)\n",
        "stcs = apply_inverse_epochs(epochs_4F, inverse_operator, lambda2, method,\n",
        "                            pick_ori=\"normal\", return_generator=True)\n",
        "\n",
        "# Get labels for FreeSurfer 'aparc' cortical parcellation with 34 labels/hemi\n",
        "labels = mne.read_labels_from_annot('fsaverage', parc='aparc',\n",
        "                                    subjects_dir=subjects_dir)[:68]\n",
        "label_colors = [label.color for label in labels]\n",
        "\n",
        "# Average the source estimates within each label using sign-flips to reduce\n",
        "# signal cancellations, also here we return a generator\n",
        "src = inverse_operator['src']\n",
        "label_ts = mne.extract_label_time_course(\n",
        "    stcs, labels,  src,allow_empty=False, mode='mean_flip', return_generator=True)\n",
        "fmin = 8.\n",
        "fmax = 13.\n",
        "sfreq = raw.info['sfreq']  # the sampling frequency\n",
        "con_methods = ['pli', 'wpli2_debiased', 'ciplv']\n",
        "if not op.exists(op.join(result_dir,'cons','40_con.lgeeg')):\n",
        "    con, freqs, times, n_epochs, n_tapers = spectral_connectivity(\n",
        "        label_ts, method=con_methods, mode='multitaper', sfreq=sfreq, fmin=fmin,\n",
        "        fmax=fmax, faverage=True, mt_adaptive=True, n_jobs=1)\n",
        "    with open(op.join(result_dir,'cons','40_con.lgeeg'),'wb') as f:\n",
        "        pickle.dump(con,f)\n",
        "else:\n",
        "    with open(op.join(result_dir,'cons','40_con.lgeeg'),'rb') as f:\n",
        "        con = pickle.load(f)\n",
        "con_res_40 = dict()\n",
        "for method, c in zip(con_methods, con):\n",
        "    con_res_40[method] = c[:, :, 0]\n",
        "\n",
        "lambda2 = 1.0 / snr ** 2\n",
        "method = \"dSPM\"  # use dSPM method (could also be MNE or sLORETA)\n",
        "stcs = apply_inverse_epochs(epochs_RF, inverse_operator, lambda2, method,\n",
        "                            pick_ori=\"normal\", return_generator=True)\n",
        "label_ts = mne.extract_label_time_course(\n",
        "    stcs, labels,  src,allow_empty=False, mode='mean_flip', return_generator=True)\n",
        "if not op.exists(op.join(result_dir,'cons','rand_con.lgeeg')):\n",
        "    con, freqs, times, n_epochs, n_tapers = spectral_connectivity(\n",
        "        label_ts, method=con_methods, mode='multitaper', sfreq=sfreq, fmin=fmin,\n",
        "        fmax=fmax, faverage=True, mt_adaptive=True, n_jobs=1)\n",
        "    with open(op.join(result_dir,'cons','rand_con.lgeeg'),'wb') as f:\n",
        "        pickle.dump(con,f)\n",
        "else:\n",
        "    with open(op.join(result_dir,'cons','rand_con.lgeeg'),'rb') as f:\n",
        "        con = pickle.load(f)\n",
        "# con is a 3D array, get the connectivity for the first (and only) freq. band\n",
        "# for each method\n",
        "con_res_rand = dict()\n",
        "for method, c in zip(con_methods, con):\n",
        "    con_res_rand[method] = c[:, :, 0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting time courses for 68 labels (mode: mean_flip)\n",
            "Connectivity computation...\n",
            "only using indices for lower-triangular matrix\n",
            "    computing connectivity for 2278 connections\n",
            "    using t=0.000s..27.000s for estimation (13501 points)\n",
            "    frequencies: 8.0Hz..13.0Hz (135 points)\n",
            "    connectivity scores will be averaged for each band\n",
            "    Using multitaper spectrum estimation with 7 DPSS windows\n",
            "    the following metrics will be computed: PLI, Debiased WPLI Square, ciPLV\n",
            "    computing connectivity for epoch 1\n",
            "    assembling connectivity matrix\n",
            "[Connectivity computation done]\n",
            "Extracting time courses for 68 labels (mode: mean_flip)\n",
            "Connectivity computation...\n",
            "only using indices for lower-triangular matrix\n",
            "    computing connectivity for 2278 connections\n",
            "    using t=0.000s..27.000s for estimation (13501 points)\n",
            "    frequencies: 8.0Hz..13.0Hz (135 points)\n",
            "    connectivity scores will be averaged for each band\n",
            "    Using multitaper spectrum estimation with 7 DPSS windows\n",
            "    the following metrics will be computed: PLI, Debiased WPLI Square, ciPLV\n",
            "    computing connectivity for epoch 1\n",
            "    assembling connectivity matrix\n",
            "[Connectivity computation done]\n",
            "Extracting time courses for 68 labels (mode: mean_flip)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-2f4fd3a0ec7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'stc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'40_stc'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.lgeeg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mstcs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     label_ts = mne.extract_label_time_course(\n\u001b[0m\u001b[1;32m     19\u001b[0m     stcs, labels,  src,allow_empty=False, mode='mean_flip', return_generator=False)\n\u001b[1;32m     20\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstcs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_peak\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhemi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lh'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-288>\u001b[0m in \u001b[0;36mextract_label_time_course\u001b[0;34m(stcs, labels, src, mode, allow_empty, return_generator, mri_resolution, verbose)\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/mne/lib/python3.9/site-packages/mne/source_estimate.py\u001b[0m in \u001b[0;36mextract_label_time_course\u001b[0;34m(stcs, labels, src, mode, allow_empty, return_generator, mri_resolution, verbose)\u001b[0m\n\u001b[1;32m   3214\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m         \u001b[0;31m# do the extraction and return a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3216\u001b[0;31m         \u001b[0mlabel_tc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_tc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3218\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_several\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/mne/lib/python3.9/site-packages/mne/source_estimate.py\u001b[0m in \u001b[0;36m_gen_extract_label_time_course\u001b[0;34m(stcs, labels, src, mode, allow_empty, mri_resolution, verbose)\u001b[0m\n\u001b[1;32m   3149\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3150\u001b[0m                     \u001b[0mthis_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvertidx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3151\u001b[0;31m                 \u001b[0mlabel_tc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3153\u001b[0m         \u001b[0;31m# extract label time series for the vol src space (only mean supported)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/mne/lib/python3.9/site-packages/mne/source_estimate.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(flip, data)\u001b[0m\n\u001b[1;32m   2842\u001b[0m _label_funcs = {\n\u001b[1;32m   2843\u001b[0m     \u001b[0;34m'mean'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mflip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2844\u001b[0;31m     \u001b[0;34m'mean_flip'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mflip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflip\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2845\u001b[0m     \u001b[0;34m'max'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mflip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2846\u001b[0m     \u001b[0;34m'pca_flip'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_pca_flip\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/mne/lib/python3.9/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   3370\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3372\u001b[0;31m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0m\u001b[1;32m   3373\u001b[0m                           out=out, **kwargs)\n\u001b[1;32m   3374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/mne/lib/python3.9/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mis_float16_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         ret = um.true_divide(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "cons_40 = []\n",
        "cons_rand = []\n",
        "act_40 = []\n",
        "act_rand = []\n",
        "\n",
        "for i in range(len(epochs_4F)):\n",
        "    snr = 1.0  # use lower SNR for single epochs\n",
        "    lambda2 = 1.0 / snr ** 2\n",
        "    method = \"dSPM\"  # use dSPM method (could also be MNE or sLORETA)  \n",
        "    if not op.exists(op.join(result_dir,'stc','40_stc'+str(i)+'.lgeeg')):\n",
        "        stcs = apply_inverse_epochs(epochs_4F[i], inverse_operator, lambda2, method,\n",
        "                                pick_ori=\"normal\", return_generator=False)\n",
        "        with open(op.join(result_dir,'stc','40_stc'+str(i)+'.lgeeg'),'wb') as f:\n",
        "            pickle.dump(stcs,f)\n",
        "    else:\n",
        "        with open(op.join(result_dir,'stc','40_stc'+str(i)+'.lgeeg'),'rb') as f:\n",
        "            stcs = pickle.load(f)\n",
        "    label_ts = mne.extract_label_time_course(\n",
        "    stcs, labels,  src,allow_empty=False, mode='mean_flip', return_generator=False)\n",
        "    _, time_max = stcs[0].get_peak(hemi='lh')\n",
        "    act_40.append(label_ts[0][:,round(time_max)])\n",
        "    fmin = 8.\n",
        "    fmax = 13.\n",
        "    sfreq = raw.info['sfreq']  # the sampling frequency\n",
        "    con_methods = ['pli', 'wpli2_debiased', 'ciplv']\n",
        "    if not op.exists(op.join(result_dir,'cons','40_con'+str(i)+'.lgeeg')):\n",
        "        con, freqs, times, n_epochs, n_tapers = spectral_connectivity(\n",
        "            label_ts, method=con_methods, mode='multitaper', sfreq=sfreq, fmin=fmin,\n",
        "            fmax=fmax, faverage=True, mt_adaptive=True, n_jobs=1)\n",
        "        with open(op.join(result_dir,'cons','40_con'+str(i)+'.lgeeg'),'wb') as f:\n",
        "            pickle.dump(con,f)\n",
        "    else:\n",
        "        with open(op.join(result_dir,'cons','40_con'+str(i)+'.lgeeg'),'rb') as f:\n",
        "            con = pickle.load(f)\n",
        "    cons_40.append(con)\n",
        "for i in range(len(epochs_RF)):\n",
        "    snr = 1.0  # use lower SNR for single epochs\n",
        "    lambda2 = 1.0 / snr ** 2\n",
        "    method = \"dSPM\"  # use dSPM method (could also be MNE or sLORETA)  \n",
        "    if not op.exists(op.join(result_dir,'stc','rand_stc'+str(i)+'.lgeeg')):\n",
        "        stcs = apply_inverse_epochs(epochs_RF[i], inverse_operator, lambda2, method,\n",
        "                                pick_ori=\"normal\", return_generator=False)\n",
        "        with open(op.join(result_dir,'stc','rand_stc'+str(i)+'.lgeeg'),'wb') as f:\n",
        "            pickle.dump(stcs,f)\n",
        "    else:\n",
        "        with open(op.join(result_dir,'stc','rand_stc'+str(i)+'.lgeeg'),'rb') as f:\n",
        "            stcs = pickle.load(f)\n",
        "    label_ts = mne.extract_label_time_course(\n",
        "    stcs, labels,  src,allow_empty=False, mode='mean_flip', return_generator=False)\n",
        "    _, time_max = stcs[0].get_peak(hemi='lh')\n",
        "    act_rand.append(label_ts[0][:,round(time_max)])\n",
        "    fmin = 8.\n",
        "    fmax = 13.\n",
        "    sfreq = raw.info['sfreq']  # the sampling frequency\n",
        "    con_methods = ['wpli2_debiased']\n",
        "    if not op.exists(op.join(result_dir,'cons','rand_con'+str(i)+'.lgeeg')):\n",
        "        con, freqs, times, n_epochs, n_tapers = spectral_connectivity(\n",
        "            label_ts, method=con_methods, mode='multitaper', sfreq=sfreq, fmin=fmin,\n",
        "            fmax=fmax, faverage=True, mt_adaptive=True, n_jobs=1)\n",
        "        with open(op.join(result_dir,'cons','rand_con'+str(i)+'.lgeeg'),'wb') as f:\n",
        "            pickle.dump(con,f)\n",
        "    else:\n",
        "        with open(op.join(result_dir,'cons','rand_con'+str(i)+'.lgeeg'),'rb') as f:\n",
        "            con = pickle.load(f)\n",
        "    cons_rand.append(con)\n",
        "cons_40=np.array(cons_40).squeeze()\n",
        "cons_rand=np.array(cons_rand).squeeze()\n",
        "act_40=np.array(act_40)\n",
        "act_rand=np.array(act_rand)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preparing the inverse operator for use...\n",
            "    Scaled noise and source covariance from nave = 1 to nave = 1\n",
            "    Created the regularized inverter\n",
            "    Created an SSP operator (subspace dimension = 1)\n",
            "    Created the whitener using a noise covariance matrix with rank 63 (1 small eigenvalues omitted)\n",
            "    Computing noise-normalization factors (dSPM)...\n",
            "[done]\n",
            "Picked 64 channels from the data\n",
            "Computing inverse...\n",
            "    Eigenleads need to be weighted ...\n",
            "Processing epoch : 1 / 1\n",
            "[done]\n",
            "Extracting time courses for 68 labels (mode: mean_flip)\n",
            "Connectivity computation...\n",
            "only using indices for lower-triangular matrix\n",
            "    computing connectivity for 2278 connections\n",
            "    using t=0.000s..27.000s for estimation (13501 points)\n",
            "    frequencies: 8.0Hz..13.0Hz (135 points)\n",
            "    connectivity scores will be averaged for each band\n",
            "    Using multitaper spectrum estimation with 7 DPSS windows\n",
            "    the following metrics will be computed: PLI, Debiased WPLI Square, ciPLV\n",
            "    computing connectivity for epoch 1\n",
            "    assembling connectivity matrix\n",
            "[Connectivity computation done]\n"
          ]
        }
      ],
      "source": [
        "# stcs = apply_inverse_epochs(epochs_4F[0], inverse_operator, lambda2, method,\n",
        "#                         pick_ori=\"normal\", return_generator=False)\n",
        "# label_ts = mne.extract_label_time_course(\n",
        "# stcs, labels,  src,allow_empty=False, mode='mean_flip', return_generator=False)\n",
        "# _, time_max = stcs[0].get_peak(hemi='lh')\n",
        "# act_40.append(label_ts[0][:,round(time_max)])\n",
        "# fmin = 8.\n",
        "# fmax = 13.\n",
        "# sfreq = raw.info['sfreq']  # the sampling frequency\n",
        "# con_methods = ['pli', 'wpli2_debiased', 'ciplv']\n",
        "# con, freqs, times, n_epochs, n_tapers = spectral_connectivity(\n",
        "#     label_ts, method=con_methods, mode='multitaper', sfreq=sfreq, fmin=fmin,\n",
        "#     fmax=fmax, faverage=True, mt_adaptive=True, n_jobs=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Make a connectivity plot\n",
        "\n",
        "Now, we visualize this connectivity using a circular graph layout.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# First, we reorder the labels based on their location in the left hemi\n",
        "label_names = [label.name for label in labels]\n",
        "\n",
        "lh_labels = [name for name in label_names if name.endswith('lh')]\n",
        "\n",
        "# Get the y-location of the label\n",
        "label_ypos = list()\n",
        "for name in lh_labels:\n",
        "    idx = label_names.index(name)\n",
        "    ypos = np.mean(labels[idx].pos[:, 1])\n",
        "    label_ypos.append(ypos)\n",
        "\n",
        "# Reorder the labels based on their location\n",
        "lh_labels = [label for (yp, label) in sorted(zip(label_ypos, lh_labels))]\n",
        "\n",
        "# For the right hemi\n",
        "rh_labels = [label[:-2] + 'rh' for label in lh_labels]\n",
        "\n",
        "# Save the plot order and create a circular layout\n",
        "node_order = list()\n",
        "node_order.extend(lh_labels[::-1])  # reverse the order\n",
        "node_order.extend(rh_labels)\n",
        "# node_order = node_order[:69]\n",
        "\n",
        "node_angles = circular_layout(label_names, node_order, start_pos=90,\n",
        "                              group_boundaries=[0, len(label_names) / 2])\n",
        "\n",
        "# Plot the graph using node colors from the FreeSurfer parcellation. We only\n",
        "# show the 300 strongest connections.\n",
        "fig,ax=plot_connectivity_circle(con_res_40['wpli2_debiased'], label_names, n_lines=300,\n",
        "                         node_angles=node_angles, node_colors=label_colors, \n",
        "                         title='All-to-All Connectivity 40 Hz '\n",
        "                               'Condition (PLI)')\n",
        "fig.savefig(op.join(result_dir,'40-connectivity.png'),facecolor='black')\n",
        "fig,ax=plot_connectivity_circle(con_res_rand['wpli2_debiased'], label_names, n_lines=300,\n",
        "                         node_angles=node_angles, node_colors=label_colors, \n",
        "                         title='All-to-All Connectivity Random '\n",
        "                               'Condition (PLI)')\n",
        "fig.savefig(op.join(result_dir,'rand-connectivity.png'),facecolor='black')\n",
        "dcon_res = con_res_40['wpli2_debiased'] - con_res_rand['wpli2_debiased']\n",
        "fig,ax=plot_connectivity_circle(np.where(dcon_res<0,0,dcon_res), label_names, n_lines=300,\n",
        "                         node_angles=node_angles, node_colors=label_colors, colormap='hot', \n",
        "                         title='All-to-All Connectivity Upregulated '\n",
        "                               '(PLI)')\n",
        "fig.savefig(op.join(result_dir,'up-connectivity.png'),facecolor='black')\n",
        "fig,ax=plot_connectivity_circle(np.where(dcon_res>0,0,-1*dcon_res), label_names, n_lines=300,\n",
        "                         node_angles=node_angles, node_colors=label_colors, colormap='gray',\n",
        "                         title='All-to-All Connectivity Downregulated '\n",
        "                               '(PLI)')\n",
        "fig.savefig(op.join(result_dir,'down-connectivity.png'),facecolor='black')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(len(epochs_4F)):\n",
        "    pd_40=pd.DataFrame(cons_40[0])\n",
        "    pd_40.columns = label_names\n",
        "    pd_40.index = label_names\n",
        "    pd_40.to_excel(op.join(result_dir,'con_stat','40_conn'+str(i)+'.xlsx'))\n",
        "for i in range(len(epochs_RF)):\n",
        "    pd_rand=pd.DataFrame(cons_rand[0])\n",
        "    pd_rand.columns = label_names\n",
        "    pd_rand.index = label_names\n",
        "    pd_rand.to_excel(op.join(result_dir,'con_stat','rand_conn'+str(i)+'.xlsx'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd_40=pd.DataFrame(act_40)\n",
        "pd_40.columns = label_names\n",
        "pd_40.to_excel(op.join(result_dir,'40_activation.xlsx'))\n",
        "pd_rand=pd.DataFrame(act_rand)\n",
        "pd_rand.columns = label_names\n",
        "pd_rand.to_excel(op.join(result_dir,'rand_activation.xlsx'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not op.exists(op.join(result_dir,'stc','rand_stc.lgeeg')):\n",
        "    stcs_rand = apply_inverse_epochs(epochs_RF, inverse_operator, lambda2, 'dSPM',\n",
        "                            pick_ori=\"normal\")\n",
        "    avg_stc_rand = np.mean(stcs_rand)\n",
        "    with open(op.join(result_dir,'stc','rand_stc.lgeeg'),'wb') as f:\n",
        "        pickle.dump(avg_stc_rand,f)\n",
        "    del stcs_rand\n",
        "else:\n",
        "    with open(op.join(result_dir,'stc','rand_stc.lgeeg'),'rb') as f:\n",
        "        avg_stc_rand = pickle.load(f)           \n",
        "if not op.exists(op.join(result_dir,'stc','rand_con.lgeeg')):\n",
        "    stcs_40 = apply_inverse_epochs(epochs_4F, inverse_operator, lambda2, 'dSPM',\n",
        "                            pick_ori=\"normal\")\n",
        "    avg_stc_40 = np.mean(stcs_40)\n",
        "    with open(op.join(result_dir,'stc','40_stc.lgeeg'),'wb') as f:\n",
        "        pickle.dump(avg_stc_40,f)\n",
        "    del stcs_40\n",
        "else:\n",
        "    with open(op.join(result_dir,'stc','40_stc.lgeeg'),'rb') as f:\n",
        "        avg_stc_40 = pickle.load(f) \n",
        "                                   \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stc = avg_stc_40\n",
        "vertno_max, time_max = stc.get_peak(hemi='lh')\n",
        "surfer_kwargs = dict(\n",
        "    hemi='lh', subjects_dir=subjects_dir,\n",
        "    clim=dict(kind='value', lims=[0, 1, 2]), views='dor',\n",
        "    initial_time=time_max, time_unit='s', size=(800, 800),backend ='matplotlib', smoothing_steps=10)\n",
        "brain = stc.plot(**surfer_kwargs)\n",
        "brain.savefig(op.join(result_dir,'activation_40_lh.png'))\n",
        "vertno_max, time_max = stc.get_peak(hemi='rh')\n",
        "surfer_kwargs = dict(\n",
        "    hemi='rh', subjects_dir=subjects_dir,\n",
        "    clim=dict(kind='value', lims=[0, 1, 2]), views='dor',\n",
        "    initial_time=10, time_unit='s', size=(800, 800),backend ='matplotlib', smoothing_steps=10)\n",
        "brain = avg_stc_40.plot(**surfer_kwargs)\n",
        "brain.savefig(op.join(result_dir,'activation_40_rh.png'))\n",
        "# brain.add_foci(vertno_max, coords_as_verts=True, hemi='lh', color='blue',\n",
        "            #    scale_factor=0.6, alpha=0.5)\n",
        "# brain.add_text(0.1, 0.9, 'dSPM (plus location of maximal activation)', 'title',\n",
        "            #    font_size=14)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stc = avg_stc_rand\n",
        "vertno_max, time_max = stc.get_peak(hemi='lh')\n",
        "surfer_kwargs = dict(\n",
        "    hemi='lh', subjects_dir=subjects_dir,\n",
        "    clim=dict(kind='value', lims=[0, 1, 2]), views='dor',\n",
        "    initial_time=time_max, time_unit='s', size=(800, 800),backend ='matplotlib', smoothing_steps=10)\n",
        "brain = stc.plot(**surfer_kwargs)\n",
        "brain.savefig(op.join(result_dir,'activation_rand_lh.png'))\n",
        "vertno_max, time_max = stc.get_peak(hemi='rh')\n",
        "surfer_kwargs = dict(\n",
        "    hemi='rh', subjects_dir=subjects_dir,\n",
        "    clim=dict(kind='value', lims=[0, 1, 2]), views='dor',\n",
        "    initial_time=10, time_unit='s', size=(800, 800),backend ='matplotlib', smoothing_steps=10)\n",
        "brain = stc.plot(**surfer_kwargs)\n",
        "brain.savefig(op.join(result_dir,'activation_rand_rh.png'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "label_ts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Make two connectivity plots in the same figure\n",
        "\n",
        "We can also assign these connectivity plots to axes in a figure. Below we'll\n",
        "show the connectivity plot using two different connectivity methods.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# fig = plt.figure(num=None, figsize=(8, 4), facecolor='black')\n",
        "# no_names = [''] * len(label_names)\n",
        "# for ii, method in enumerate([con_methods]):\n",
        "#     plot_connectivity_circle(con_res[method], no_names, n_lines=300,\n",
        "#                              node_angles=node_angles, node_colors=label_colors,\n",
        "#                              title=method, padding=0, fontsize_colorbar=6,\n",
        "#                              fig=fig, subplot=(1, 3, ii + 1))\n",
        "\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save the figure (optional)\n",
        "\n",
        "By default matplotlib does not save using the facecolor, even though this was\n",
        "set when the figure was generated. If not set via savefig, the labels, title,\n",
        "and legend will be cut off from the output png file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# fname_fig = data_path + '/MEG/sample/plot_inverse_connect.png'\n",
        "# fig.savefig(fname_fig, facecolor='black')"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "e3970cf2a056ed71c6703e76baeca137440641ad1b48b7e7a1b0e3e35696df1b"
    },
    "kernelspec": {
      "display_name": "Python 3.9.5 64-bit ('mne': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}