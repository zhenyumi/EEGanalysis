{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('mne': conda)"
  },
  "interpreter": {
   "hash": "e3970cf2a056ed71c6703e76baeca137440641ad1b48b7e7a1b0e3e35696df1b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Initialize"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authors: Martin Luessi <mluessi@nmr.mgh.harvard.edu>\n",
    "#          Alexandre Gramfort <alexandre.gramfort@inria.fr>\n",
    "#          Nicolas P. Rougier (graph code borrowed from his matplotlib gallery)\n",
    "#\n",
    "# License: BSD (3-clause)\n",
    "\n",
    "import numpy as np\n",
    "import os.path as op\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from langouEEG import *\n",
    "\n",
    "import mne\n",
    "import pickle\n",
    "from mne.datasets import sample\n",
    "from mne.minimum_norm import apply_inverse_epochs, read_inverse_operator\n",
    "from mne.connectivity import spectral_connectivity\n",
    "from mne.viz import circular_layout, plot_connectivity_circle\n",
    "import mne\n",
    "from mne.datasets import eegbci\n",
    "from mne.datasets import fetch_fsaverage\n",
    "from mne.datasets import sample\n",
    "from mne.minimum_norm import make_inverse_operator, apply_inverse\n",
    "from mne.minimum_norm import write_inverse_operator\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa\n",
    "import mne\n",
    "\n",
    "sample_data_folder = mne.datasets.sample.data_path()\n",
    "dataRoot = \"/data/home/viscent/Light\"\n",
    "# Download fsaverage files\n",
    "fs_dir = fetch_fsaverage(verbose=True)\n",
    "isMale = False\n",
    "result_dir = op.join(dataRoot,'result','male' if isMale else 'female')\n",
    "subjects_dir = op.dirname(fs_dir)\n",
    "\n",
    "# The files live in:\n",
    "subject = 'fsaverage'\n",
    "trans = 'fsaverage'  # MNE has a built-in fsaverage transformation\n",
    "src = op.join(fs_dir, 'bem', 'fsaverage-ico-5-src.fif')\n",
    "bem = op.join(fs_dir, 'bem', 'fsaverage-5120-5120-5120-bem-sol.fif')\n",
    "print(__doc__)"
   ]
  },
  {
   "source": [
    "# Load data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "epochs_4F = dict()\n",
    "epochs_RF = dict()\n",
    "for subject_name in range(1,21):\n",
    "    if not (isMale ^ (subject_name in [7,8,11,17])):\n",
    "        continue\n",
    "    if subject_name<10:\n",
    "        subject_name='S0'+str(subject_name)\n",
    "    else:\n",
    "        subject_name='S'+str(subject_name)\n",
    "    with open(dataRoot+'/clean_data_av/'+subject_name+'_clean.lgeeg','rb') as f:\n",
    "        raw=pickle.load(f)\n",
    "    events, event_dict=extractEvents(raw)\n",
    "    picks = mne.pick_types(raw.info, meg=False, eeg=True, stim=False, eog=True,\n",
    "                        exclude='bads')\n",
    "    epoch_RR,epoch_RF,epoch_4R,epoch_4F = extractEpochs(raw,events,picks)\n",
    "    epochs_4F[subject_name]=epoch_4F\n",
    "    epochs_RF[subject_name]=epoch_RF\n",
    "    if not op.exists(os.path.join(dataRoot,'fwd_solution.lgeeg')):\n",
    "        fwd = mne.make_forward_solution(raw.info, trans=trans, src=src,\n",
    "                                        bem=bem, eeg=True, mindist=5.0, n_jobs=1)\n",
    "        print(fwd)\n",
    "        mne.write_forward_solution(os.path.join(dataRoot,'fwd_solution.lgeeg'),fwd,overwrite=True)\n",
    "    else:\n",
    "        fwd = mne.read_forward_solution(os.path.join(dataRoot,'fwd_solution.lgeeg'))\n",
    "    data_path = sample.data_path()\n",
    "    # subjects_dir = data_path + '/subjects'\n",
    "    fname_inv = os.path.join(dataRoot,'inv_operators',subject_name+'_inv.lgeeg')\n",
    "    fname_cov = os.path.join(dataRoot,'noise_covariance',subject_name+'_cov.lgeeg')\n",
    "    # subject = 'sample'\n",
    "    # fname_raw = data_path + '/MEG/sample/sample_audvis_filt-0-40_raw.fif'\n",
    "    # fname_event = data_path + '/MEG/sample/sample_audvis_filt-0-40_raw-eve.fif'\n",
    "    # Pick MEG channels\n",
    "    picks = mne.pick_types(raw.info, meg=False, eeg=True, stim=False, eog=True,\n",
    "                        exclude='bads')\n",
    "    epoch_RR,epoch_RF,epoch_4R,epoch_4F = extractEpochs(raw,events,picks)\n",
    "    # evoked_4F = epoch_4F.average().pick('eeg')\n",
    "    # Define epochs for left-auditory condition\n",
    "    # event_id, tmin, tmax = 1, -0.2, 0.5\n",
    "    # epochs = mne.Epochs(raw, events, event_id, tmin, tmax, picks=picks,\n",
    "                        # baseline=(None, 0), reject=dict(mag=4e-12, grad=4000e-13,\n",
    "                        #                                 eog=150e-6))\n",
    "\n",
    "    if not os.path.exists(fname_inv):  \n",
    "        noise_cov = mne.compute_covariance(\n",
    "            epoch_RR, tmax=80., method=['shrunk', 'empirical'], rank=None, verbose=True)\n",
    "        mne.write_cov(fname_cov,noise_cov)\n",
    "    else:   \n",
    "    # Load data\n",
    "        noise_cov = mne.read_cov(fname_cov)\n",
    "    \n",
    "\n",
    "\n",
    "    if not os.path.exists(fname_inv):  \n",
    "        inverse_operator = make_inverse_operator(\n",
    "            raw.info, fwd, noise_cov, loose=0.2, depth=0.8)\n",
    "        write_inverse_operator(fname_inv,inverse_operator)\n",
    "    else:   \n",
    "    # Load data\n",
    "        inverse_operator = read_inverse_operator(fname_inv)"
   ]
  },
  {
   "source": [
    "# Source Estimation\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cons_40 = []\n",
    "cons_rand = []\n",
    "for subject_name,_ in epochs_4F.items():\n",
    "    # Compute inverse solution and for each epoch. By using \"return_generator=True\"\n",
    "    # stcs will be a generator object instead of a list.\n",
    "    epoch_4F = epochs_4F[subject_name]\n",
    "    epoch_RF = epochs_RF[subject_name]\n",
    "    result_dir = op.join(dataRoot,'result','male' if isMale else 'female',subject_name)\n",
    "    fname_stc_4F = op.join(result_dir,subject_name+'_stc_4F.lgeeg')\n",
    "    fname_stc_RF = op.join(result_dir,subject_name+'_stc_RF.lgeeg')\n",
    "    fname_tl_4F = op.join(result_dir,subject_name+'_tl_4F.lgeeg')\n",
    "    fname_tl_RF = op.join(result_dir,subject_name+'_tl_RF.lgeeg')\n",
    "    if not os.path.exists(result_dir):\n",
    "        os.mkdir(result_dir)\n",
    "\n",
    "    snr = 1.0  # use lower SNR for single epochs\n",
    "    lambda2 = 1.0 / snr ** 2\n",
    "    method = \"dSPM\"  # use dSPM method (could also be MNE or sLORETA)\n",
    "    # Get labels for FreeSurfer 'aparc' cortical parcellation with 34 labels/hemi\n",
    "    labels = mne.read_labels_from_annot('fsaverage', parc='aparc',\n",
    "                                        subjects_dir=subjects_dir)[:68]\n",
    "    label_colors = [label.color for label in labels]\n",
    "    # Average the source estimates within each label using sign-flips to reduce\n",
    "    # signal cancellations, also here we return a generator\n",
    "    src = inverse_operator['src']\n",
    "    if op.exists(fname_tl_4F):\n",
    "        with open(fname_tl_4F,'rb') as f:\n",
    "            label_ts = pickle.load(f)\n",
    "    else:\n",
    "        stcs = apply_inverse_epochs(epoch_4F, inverse_operator, lambda2, method,\n",
    "                                    pick_ori=\"normal\", return_generator=False)\n",
    "        label_ts = mne.extract_label_time_course(\n",
    "            stcs, labels,  src,allow_empty=False, mode='mean_flip', return_generator=False)\n",
    "        with open(fname_tl_4F,'wb') as f:\n",
    "            pickle.dump(label_ts,f)\n",
    "    fmin = 8.\n",
    "    fmax = 13.\n",
    "    sfreq = raw.info['sfreq']  # the sampling frequency\n",
    "    con_methods = ['pli', 'wpli2_debiased', 'ciplv']\n",
    "    if not os.path.exists(op.join(result_dir,'cons')):\n",
    "        os.mkdir(op.join(result_dir,'cons'))\n",
    "    if not op.exists(op.join(result_dir,'cons','40_con.lgeeg')):\n",
    "        con, freqs, times, n_epochs, n_tapers = spectral_connectivity(\n",
    "            label_ts, method=con_methods, mode='multitaper', sfreq=sfreq, fmin=fmin,\n",
    "            fmax=fmax, faverage=True, mt_adaptive=True, n_jobs=1)\n",
    "        with open(op.join(result_dir,'cons','40_con.lgeeg'),'wb') as f:\n",
    "            pickle.dump(con,f)\n",
    "    else:\n",
    "        with open(op.join(result_dir,'cons','40_con.lgeeg'),'rb') as f:\n",
    "            con = pickle.load(f)\n",
    "    label_names = [label.name for label in labels]\n",
    "    con = np.squeeze(con)\n",
    "    cons_40.append(con)\n",
    "    pd_40=pd.DataFrame(con[1])\n",
    "    pd_40.columns = label_names\n",
    "    pd_40.index = label_names\n",
    "    pd_40.to_excel(op.join(result_dir,'40_conn.xlsx'))\n",
    "    con_40 = con.copy()\n",
    "    pd_40=pd.DataFrame(np.mean(label_ts,axis=2))\n",
    "    pd_40.columns = label_names\n",
    "    pd_40.to_excel(op.join(result_dir,'40_activation.xlsx'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    lambda2 = 1.0 / snr ** 2\n",
    "    method = \"dSPM\"  # use dSPM method (could also be MNE or sLORETA)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if op.exists(fname_tl_RF):\n",
    "        with open(fname_tl_RF,'rb') as f:\n",
    "            label_ts = pickle.load(f)\n",
    "    else:\n",
    "        stcs = apply_inverse_epochs(epoch_RF, inverse_operator, lambda2, method,\n",
    "                                    pick_ori=\"normal\", return_generator=False)\n",
    "        label_ts = mne.extract_label_time_course(\n",
    "            stcs, labels,  src,allow_empty=False, mode='mean_flip', return_generator=False)\n",
    "        with open(fname_tl_RF,'wb') as f:\n",
    "            pickle.dump(label_ts,f)\n",
    "\n",
    "    \n",
    "    if not op.exists(op.join(result_dir,'cons','rand_con.lgeeg')):\n",
    "        con, freqs, times, n_epochs, n_tapers = spectral_connectivity(\n",
    "            label_ts, method=con_methods, mode='multitaper', sfreq=sfreq, fmin=fmin,\n",
    "            fmax=fmax, faverage=True, mt_adaptive=True, n_jobs=1)\n",
    "        with open(op.join(result_dir,'cons','rand_con.lgeeg'),'wb') as f:\n",
    "            pickle.dump(con,f)\n",
    "    else:\n",
    "        with open(op.join(result_dir,'cons','rand_con.lgeeg'),'rb') as f:\n",
    "            con = pickle.load(f)\n",
    "    # con is a 3D array, get the connectivity for the first (and only) freq. band\n",
    "    # for each method\n",
    "\n",
    "    con = np.squeeze(con)\n",
    "    cons_rand.append(con)\n",
    "    con_rand = con.copy()\n",
    "    pd_rand=pd.DataFrame(con[1])\n",
    "    pd_rand.columns = label_names\n",
    "    pd_rand.index = label_names\n",
    "    pd_rand.to_excel(op.join(result_dir,'rand_conn.xlsx'))\n",
    "    pd_delta=pd.DataFrame(con_40[1]-con_rand[1])\n",
    "    pd_delta.columns = label_names\n",
    "    pd_delta.index = label_names\n",
    "    pd_delta.to_excel(op.join(result_dir,'delta_conn.xlsx'))\n",
    "    pd_rand=pd.DataFrame(np.mean(label_ts,axis=2))\n",
    "    pd_rand.columns = label_names\n",
    "    pd_rand.to_excel(op.join(result_dir,'rand_activation.xlsx'))\n",
    "cons_40 = np.array(cons_40)[:,1,...]\n",
    "cons_rand = np.array(cons_rand)[:,1,...]"
   ]
  }
 ]
}