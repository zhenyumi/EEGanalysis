{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import os.path as op\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from langouEEG import *\n",
    "\n",
    "import mne\n",
    "import pickle\n",
    "from mne.datasets import sample\n",
    "from mne.minimum_norm import apply_inverse_epochs, read_inverse_operator\n",
    "from mne.connectivity import spectral_connectivity\n",
    "from mne.viz import circular_layout, plot_connectivity_circle\n",
    "import mne\n",
    "from mne.datasets import eegbci\n",
    "from mne.datasets import fetch_fsaverage\n",
    "from mne.datasets import sample\n",
    "from mne.minimum_norm import make_inverse_operator, apply_inverse\n",
    "from mne.minimum_norm import write_inverse_operator\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa\n",
    "import mne\n",
    "from mne.epochs import equalize_epoch_counts\n",
    "\n",
    "import os.path as op\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import randn\n",
    "from scipy import stats as stats\n",
    "\n",
    "import mne\n",
    "from mne.epochs import equalize_epoch_counts\n",
    "from mne.stats import (spatio_temporal_cluster_1samp_test, spatio_temporal_cluster_test,\n",
    "                       summarize_clusters_stc)\n",
    "from mne.minimum_norm import apply_inverse, read_inverse_operator\n",
    "from mne.datasets import sample\n",
    "from tqdm import trange\n",
    "\n",
    "sample_data_folder = mne.datasets.sample.data_path()\n",
    "dataRoot = \"/data/home/viscent/Light\"\n",
    "# Download fsaverage files\n",
    "fs_dir = fetch_fsaverage(verbose=True)\n",
    "isMale = True\n",
    "result_dir = op.join(dataRoot,'result','male' if isMale else 'female')\n",
    "subjects_dir = op.dirname(fs_dir)\n",
    "\n",
    "# The files live in:\n",
    "subject = 'fsaverage'\n",
    "trans = 'fsaverage'  # MNE has a built-in fsaverage transformation\n",
    "src = op.join(fs_dir, 'bem', 'fsaverage-ico-5-src.fif')\n",
    "bem = op.join(fs_dir, 'bem', 'fsaverage-5120-5120-5120-bem-sol.fif')\n",
    "print(__doc__)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# load data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "epochs_4F = []\n",
    "epochs_RF = []\n",
    "epochs_RR = []\n",
    "for subject_name in range(1,21):\n",
    "    if not (isMale ^ (subject_name in [7,8,11,17])):\n",
    "        continue\n",
    "    if subject_name<10:\n",
    "        subject_name='S0'+str(subject_name)\n",
    "    else:\n",
    "        subject_name='S'+str(subject_name)\n",
    "    with open(dataRoot+'/clean_data_av/'+subject_name+'_clean.lgeeg','rb') as f:\n",
    "        raw=pickle.load(f)\n",
    "    raw.set_channel_types({'Trigger':'stim','VEO':'eog'})\n",
    "    raw.set_eeg_reference(projection=True)\n",
    "    events, event_dict=extractEvents(raw)\n",
    "    picks = mne.pick_types(raw.info, meg=False, eeg=True, stim=False, eog=True,\n",
    "                        exclude='bads')\n",
    "    epoch_RR,epoch_RF,epoch_4R,epoch_4F = extractEpochs(raw,events,picks)\n",
    "    epochs_4F.append(epoch_4F)\n",
    "    epochs_RF.append(epoch_RF)\n",
    "    epochs_RR.append(epoch_RR)\n",
    "epochs_4F = mne.concatenate_epochs(epochs_4F)\n",
    "epochs_RF = mne.concatenate_epochs(epochs_RF)\n",
    "epochs_RR = mne.concatenate_epochs(epochs_RR)\n",
    "equalize_epoch_counts([epochs_4F, epochs_RF,epochs_RR])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Read forward"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "subject_name='S15'\n",
    "with open(dataRoot+'/clean_data_av/'+subject_name+'_clean.lgeeg','rb') as f:\n",
    "    raw=pickle.load(f)\n",
    "raw.set_channel_types({'Trigger':'stim','VEO':'eog'})\n",
    "raw.set_eeg_reference(projection=True)\n",
    "events, event_dict=extractEvents(raw)\n",
    "if not op.exists(os.path.join(dataRoot,'fwd_solutions',subject_name+'_fwd.lgeeg')):\n",
    "    fwd = mne.make_forward_solution(raw.info, trans=trans, src=src,\n",
    "                                    bem=bem, eeg=True, mindist=5.0, n_jobs=1)\n",
    "    print(fwd)\n",
    "    mne.write_forward_solution(os.path.join(dataRoot,'fwd_solutions',subject_name+'_fwd.lgeeg'),fwd,overwrite=True)\n",
    "else:\n",
    "    fwd = mne.read_forward_solution(os.path.join(dataRoot,'fwd_solutions',subject_name+'_fwd.lgeeg'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## compute noise covariance and inverse operators"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fname_inv = os.path.join(dataRoot,'inv_operators.lgeeg')\n",
    "fname_cov = os.path.join(dataRoot,'noise_covariance.lgeeg')\n",
    "if not os.path.exists(fname_cov):  \n",
    "    noise_cov = mne.compute_covariance(\n",
    "        epochs_RR, tmax=80., method=['shrunk', 'empirical'], rank=None, verbose=True)\n",
    "    mne.write_cov(fname_cov,noise_cov)\n",
    "else:   \n",
    "# Load data\n",
    "    noise_cov = mne.read_cov(fname_cov)\n",
    "if not os.path.exists(fname_inv):  \n",
    "    inverse_operator = make_inverse_operator(\n",
    "        raw.info, fwd, noise_cov, loose=0.2, depth=0.8)\n",
    "    write_inverse_operator(fname_inv,inverse_operator)\n",
    "else:   \n",
    "# Load data\n",
    "    inverse_operator = read_inverse_operator(fname_inv)\n",
    "src = inverse_operator['src']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Source estimate"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "stcs_40 = []\n",
    "stcs_rand = []\n",
    "snr = 1.0  # use lower SNR for single epochs\n",
    "lambda2 = 1.0 / snr ** 2\n",
    "if not op.exists(op.join(result_dir, 'stc')):\n",
    "    op.makedirs(op.join(result_dir, 'stc'))\n",
    "method = \"dSPM\"  # use dSPM method (could also be MNE or sLORETA) \n",
    "if not op.exists(op.join(result_dir,'stc','40_stc.lgeeg')):\n",
    "    epochs = epochs_4F.crop(10,15)\n",
    "    stcs = apply_inverse_epochs(epochs, inverse_operator, lambda2, method,\n",
    "                            pick_ori=\"normal\", return_generator=False)\n",
    "    with open(op.join(result_dir,'stc','40_stc.lgeeg'),'wb') as f:\n",
    "        pickle.dump(stcs,f)\n",
    "    stcs_40 = stcs\n",
    "else:\n",
    "    with open(op.join(result_dir,'stc','40_stc.lgeeg'),'rb') as f:\n",
    "        stcs_40 = pickle.load(f)\n",
    "\n",
    "\n",
    "\n",
    "if not op.exists(op.join(result_dir,'stc','rand_stc.lgeeg')):\n",
    "    epochs = epochs_RF.crop(10,15)\n",
    "    stcs = apply_inverse_epochs(epochs, inverse_operator, lambda2, method,\n",
    "                            pick_ori=\"normal\", return_generator=False)\n",
    "    with open(op.join(result_dir,'stc','rand_stc.lgeeg'),'wb') as f:\n",
    "        pickle.dump(stcs,f)\n",
    "    stcs_rand = stcs\n",
    "else:\n",
    "    with open(op.join(result_dir,'stc','rand_stc.lgeeg'),'rb') as f:\n",
    "        stcs_rand = pickle.load(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "stcs_40_np = []\n",
    "for stc in stcs_40:\n",
    "    stcs_40_np.append(stc.data)\n",
    "stcs_40_np = np.array(stcs_40_np)\n",
    "stcs_rand_np = []\n",
    "for stc in stcs_rand:\n",
    "    stcs_rand_np.append(stc.data)\n",
    "stcs_rand_np = np.array(stcs_rand_np)\n",
    "del stcs_40, stcs_rand"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X = np.array([stcs_40_np,stcs_rand_np])\n",
    "X = X.transpose(2,3,1,0)\n",
    "del stcs_40_np, stcs_rand_np\n",
    "\n",
    "\n",
    "n_vertices_sample, n_times = X.shape[0], X.shape[1]\n",
    "n_subjects = X.shape[2]\n",
    "p_threshold = 0.001\n",
    "t_threshold = -stats.distributions.t.ppf(p_threshold / 2., n_subjects - 1)\n",
    "\n",
    "fsave_vertices = [s['vertno'] for s in src]\n",
    "morph_mat = mne.compute_source_morph(\n",
    "    src=inverse_operator['src'], subject_to='fsaverage',\n",
    "    spacing=fsave_vertices, subjects_dir=subjects_dir).morph_mat\n",
    "print('Reshaping')\n",
    "n_vertices_fsave = morph_mat.shape[0]\n",
    "#    We have to change the shape for the dot() to work properly\n",
    "X = X.reshape(n_vertices_sample, n_times * n_subjects * 2)\n",
    "print('Morphing data.')\n",
    "X = morph_mat.dot(X)  # morph_mat is a sparse matrix\n",
    "X = X.reshape(n_vertices_fsave, n_times, n_subjects, 2)\n",
    "X = np.abs(X)  # only magnitude\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X = [X[:, :, :, 0].transpose([2, 1, 0]), X[:, :, :, 1].transpose([2, 1, 0])]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "# X = X[:, :, :, 0] - X[:, :, :, 1]  # make paired contrast\n",
    "# X = np.transpose(X, [2, 1, 0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import gc\n",
    "gc.collect()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compute statistic"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Computing adjacency.')\n",
    "adjacency = mne.spatial_src_adjacency(src)\n",
    "\n",
    "print('Clustering.')\n",
    "    # spatio_temporal_cluster_1samp_test(X, adjacency=adjacency, n_jobs=2,\n",
    "mne.set_cache_dir(op.join(dataRoot, 'cache'))\n",
    "T_obs, clusters, cluster_p_values, H0 = clu_40 = \\\n",
    "    spatio_temporal_cluster_test(X, adjacency=adjacency, n_jobs=20,\n",
    "                                       threshold=t_threshold, buffer_size=1,\n",
    "                                       verbose=True)\n",
    "good_cluster_inds = np.where(cluster_p_values < 0.05)[0]\n",
    "print('Visualizing clusters.')\n",
    "\n",
    "#    Now let's build a convenient representation of each cluster, where each\n",
    "#    cluster becomes a \"time point\" in the SourceEstimate\n",
    "stc_all_cluster_vis = summarize_clusters_stc(clu_40, tstep=tstep, backend='matplotlib',\n",
    "                                             vertices=fsave_vertices,\n",
    "                                             subject='fsaverage')\n",
    "\n",
    "#    Let's actually plot the first \"time point\" in the SourceEstimate, which\n",
    "#    shows all the clusters, weighted by duration.\n",
    "subjects_dir = op.join(data_path, 'subjects')\n",
    "# blue blobs are for condition A < condition B, red for A > B\n",
    "brain = stc_all_cluster_vis.plot(\n",
    "    hemi='both', views='lateral', subjects_dir=subjects_dir,\n",
    "    time_label='temporal extent (ms)', size=(800, 800),\n",
    "    smoothing_steps=5, clim=dict(kind='value', pos_lims=[0, 1, 40]))\n",
    "brain.save_image('clusters0.001.png')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}